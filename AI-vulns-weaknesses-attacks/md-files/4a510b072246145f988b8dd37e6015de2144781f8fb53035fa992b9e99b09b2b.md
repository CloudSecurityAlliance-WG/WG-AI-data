3/7/24, 2:57 PM CWE - CWE-359: Exposure of Private Personal Information to an Unauthorized Actor (4.14)
https://cwe.mitre.org/data/deﬁnitions/359.html 1/4
Common W eakness Enumeration
A community-developed list of SW & HW weaknesses that can become
vulnerabilities
Home Search
CWE-359: Exposure of Private Personal Information to an Unauthorized Actor
Weakness ID: 359
Vulnerability Mapping: 
View customized information:
 Description
The product does not properly prevent a person's private, personal information from being accessed by actors who either (1) are not
explicitly authorized to access the information or (2) do not have the implicit consent of the person about whom the information is
collected.
 Extended Description
There are many types of sensitive information that products must protect from attackers, including system data, communications,
configuration, business secrets, intellectual property , and an individual's personal (private) information. Private personal information
may include a password, phone number , geographic location, personal messages, credit card number , etc. Private information is
important to consider whether the person is a user of the product, or part of a data set that is processed by the product. An exposure
of private information does not necessarily prevent the product from working properly , and in fact the exposure might be intended by
the developer , e.g. as part of data sharing with other organizations. However , the exposure of personal private information can still be
undesirable or explicitly prohibited by law or regulation.
Some types of private information include:
Government identifiers, such as Social Security Numbers
Contact information, such as home addresses and telephone numbers
Geographic location - where the user is (or was)
Employment history
Financial data - such as credit card numbers, salary , bank accounts, and debts
Pictures, video, or audio
Behavioral patterns - such as web surfing history , when certain activities are performed, etc.
Relationships (and types of relationships) with others - family , friends, contacts, etc.
Communications - e-mail addresses, private messages, text messages, chat logs, etc.
Health - medical conditions, insurance status, prescription records
Account passwords and other credentials
Some of this information may be characterized as PII (Personally Identifiable Information), Protected Health Information (PHI), etc.
Categories of private information may overlap or vary based on the intended usage or the policies and practices of a particular
industry .
Sometimes data that is not labeled as private can have a privacy implication in a dif ferent context. For example, student identification
numbers are usually not considered private because there is no explicit and publicly-available mapping to an individual student's
personal information. However , if a school generates identification numbers based on student social security numbers, then the
identification numbers should be considered private.
 Alternate T erms
Privacy violation
Privacy leak
Privacy leakage
 Relationships
 Relevant to the view "Research Concepts" (CWE-1000)
Nature Type ID Name
ChildOf 200 Exposure of Sensitive Information to an Unauthorized Actor
 Relevant to the view "Software Development" (CWE-699)
Nature Type ID Name
MemberOf 199 Information Management Errors
 Relevant to the view "Architectural Concepts" (CWE-1008)
 Modes Of Introduction
Phase NoteAbout ▼ CWE List ▼ Mapping ▼ Top-N Lists ▼ Community ▼ News ▼
ALLOWED
Abstraction: Base
Conceptual OperationalMapping
FriendlyComplete Custom
3/7/24, 2:57 PM CWE - CWE-359: Exposure of Private Personal Information to an Unauthorized Actor (4.14)
https://cwe.mitre.org/data/deﬁnitions/359.html 2/4Architecture and DesignOMISSION: This weakness is caused by missing a security tactic during the architecture and design
phase.
Implementation
Operation
 Applicable Platforms
Languages
Class: Not Language-Specific (Undetermined Prevalence)
Technologies
Class: Mobile (Undetermined Prevalence)
 Common Consequences
Scope Impact Likelihood
ConfidentialityTechnical Impact: Read Application Data
 Demonstrative Examples
Example 1
The following code contains a logging statement that tracks the contents of records added to a database by storing them in a log file.
Among other values that are stored, the getPassword() function returns the user-supplied plaintext password associated with the
account.
The code in the example above logs a plaintext password to the filesystem. Although many developers trust the filesystem as a safe
storage location for data, it should not be trusted implicitly , particularly when privacy is a concern.
Example 2
This code uses location to determine the user's current US State location.
First the application must declare that it requires the ACCESS\_FINE\_LOCA TION permission in the application's manifest.xml:
During execution, a call to getLastLocation() will return a location based on the application's location permissions. In this case the
application has permission for the most accurate location possible:
While the application needs this information, it does not need to use the ACCESS\_FINE\_LOCA TION permission, as the
ACCESS\_COARSE\_LOCA TION permission will be suf ficient to identify which US state the user is in.
Example 3
In 2004, an employee at AOL sold approximately 92 million private customer e-mail addresses to a spammer marketing an of fshore
gambling web site [ REF-338 ]. In response to such high-profile exploits, the collection and management of private data is becoming
increasingly regulated.
 Potential Mitigations
Phase: Requirements
Identify and consult all relevant regulations for personal privacy . An organization may be required to comply with certain federal
and state regulations, depending on its location, the type of business it conducts, and the nature of any private data it handles.
Regulations may include Safe Harbor Privacy Framework [ REF-340 ], Gramm-Leach Bliley Act (GLBA) [ REF-341 ], Health
Insurance Portability and Accountability Act (HIP AA) [ REF-342 ], General Data Protection Regulation (GDPR) [ REF-1047 ],
California Consumer Privacy Act (CCP A) [REF-1048 ], and others.
Phase: Architecture and Design
Carefully evaluate how secure design may interfere with privacy , and vice versa. Security and privacy concerns often seem to
compete with each other . From a security perspective, all important operations should be recorded so that any anomalous
activity can later be identified. However , when private data is involved, this practice can in fact create risk. Although there are
many ways in which private data can be handled unsafely , a common risk stems from misplaced trust. Programmers often trust
(bad code) Example Language: C# 
pass = GetPassword();
...
dbmsLog.WriteLine(id + ":" + pass + ":" + type + ":" + tstamp);
(bad code) Example Language: XML 

(bad code) Example Language: Java 
locationClient = new LocationClient(this, this, this);
locationClient.connect();
Location userCurrLocation;
userCurrLocation = locationClient.getLastLocation();
deriveStateFromCoords(userCurrLocation);3/7/24, 2:57 PM CWE - CWE-359: Exposure of Private Personal Information to an Unauthorized Actor (4.14)
https://cwe.mitre.org/data/deﬁnitions/359.html 3/4the operating environment in which a program runs, and therefore believe that it is acceptable store private information on the
file system, in the registry , or in other locally-controlled resources. However , even if access to certain resources is restricted, this
does not guarantee that the individuals who do have access can be trusted.
 Detection Methods
Architecture or Design Review
Private personal data can enter a program in a variety of ways:
Directly from the user in the form of a password or personal information
Accessed from a database or other data store by the application
Indirectly from a partner or other third party
If the data is written to an external location - such as the console, file system, or network - a privacy violation may occur .
Effectiveness: High
Automated Static Analysis
Automated static analysis, commonly referred to as Static Application Security Testing (SAST), can find some instances of this
weakness by analyzing source code (or binary/compiled code) without having to execute it. Typically , this is done by building a
model of data flow and control flow , then searching for potentially-vulnerable patterns that connect "sources" (origins of input)
with "sinks" (destinations where the data interacts with external components, a lower layer such as the OS, etc.)
Effectiveness: High
 Memberships
Nature Type ID Name
MemberOf 254 7PK - Security Features
MemberOf 857 The CER T Oracle Secure Coding Standard for Java (2011) Chapter 14 - Input Output (FIO)
MemberOf 975 SFP Secondary Cluster: Architecture
MemberOf 1029 OWASP Top Ten 2017 Category A3 - Sensitive Data Exposure
MemberOf 1147 SEI CER T Oracle Secure Coding Standard for Java - Guidelines 13. Input Output (FIO)
MemberOf 1340 CISQ Data Protection Measures
MemberOf 1345 OWASP Top Ten 2021 Category A01:2021 - Broken Access Control
MemberOf 1417 Comprehensive Categorization: Sensitive Information Exposure
 Vulnerability Mapping Notes
Usage: ALLOWED (this CWE ID could be used to map to real-world vulnerabilities)
Reason: Acceptable-Use
Rationale:
This CWE entry is at the Base level of abstraction, which is a preferred level of abstraction for mapping to the root causes of
vulnerabilities.
Comments:
Carefully read both the name and description to ensure that this mapping is an appropriate fit. Do not try to 'force' a mapping to a
lower-level Base/V ariant simply to comply with this preferred level of abstraction.
 Notes
Maintenance
This entry overlaps many other entries that are not organized around the kind of sensitive information that is exposed. However ,
because privacy is treated with such importance due to regulations and other factors, and it may be useful for weakness-finding
tools to highlight capabilities that detect personal private information instead of system information, it is not clear whether - and how -
this entry should be deprecated.
 Taxonomy Mappings
Mapped T axonomy Name Node ID Fit Mapped Node Name
7 Pernicious Kingdoms Privacy V iolation
The CER T Oracle Secure
Coding Standard for Java
(2011)FIO13-J Do not log sensitive information outside a trust boundary
 Related Attack Patterns
CAPEC-ID Attack Pattern Name
CAPEC-464 Evercookie
CAPEC-467 Cross Site Identification
CAPEC-498 Probe iOS Screenshots
CAPEC-508 Shoulder Surfing
 References
3/7/24, 2:57 PM CWE - CWE-359: Exposure of Private Personal Information to an Unauthorized Actor (4.14)
https://cwe.mitre.org/data/deﬁnitions/359.html 4/4[REF-6] Katrina Tsipenyuk, Brian Chess and Gary McGraw . "Seven Pernicious Kingdoms: A Taxonomy of Software Security
Errors". NIST Workshop on Software Security Assurance Tools Techniques and Metrics. NIST . 2005-11-07.
.
[REF-338] J. Oates. "AOL man pleads guilty to selling 92m email addies". The Register . 2005.
. URL validated: 2023-04-07 .
[REF-339] NIST . "Guide to Protecting the Confidentiality of Personally Identifiable Information (SP 800-122)". 2010-04.
. URL validated: 2023-04-07 .
[REF-340] U.S. Department of Commerce. "Safe Harbor Privacy Framework".
. URL validated: 2023-04-07 .
[REF-341] Federal Trade Commission. "Financial Privacy: The Gramm-Leach Bliley Act (GLBA)". < https://www .ftc.gov/business-
guidance/privacy-security/gramm-leach-bliley-act >. URL validated: 2023-04-07 .
[REF-342] U.S. Department of Human Services. "Health Insurance Portability and Accountability Act (HIP AA)".
. URL validated: 2023-04-07 .
[REF-343] Government of the State of California. "California SB-1386". 2002. < http://info.sen.ca.gov/pub/01-02/bill/sen/sb\_1351-
1400/sb\_1386\_bill\_20020926\_chaptered.html >.
[REF-267] Information Technology Laboratory , National Institute of Standards and Technology . "SECURITY REQUIREMENTS
FOR CR YPTOGRAPHIC MODULES". 2001-05-25.
. URL validated: 2023-04-07 .
[REF-172] Chris W ysopal. "Mobile App Top 10 List". 2010-12-13. < https://www .veracode.com/blog/2010/12/mobile-app-top-10-
list>. URL validated: 2023-04-07 .
[REF-1047] Wikipedia. "General Data Protection Regulation".
.
[REF-1048] State of California Department of Justice, Of fice of the Attorney General. "California Consumer Privacy Act (CCP A)".
.
 Content History
 Submissions
Submission Date Submitter Organization
2006-07-19
(CWE Draft 3, 2006-07-19)7 Pernicious Kingdoms
 Modifications
 Previous Entry Names