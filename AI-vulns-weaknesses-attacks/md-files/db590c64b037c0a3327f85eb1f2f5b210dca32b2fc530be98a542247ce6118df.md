3/22/24, 2:25 PM Backdoor ML Model | MITRE ATLAS™
https://atlas.mitre.org/techniques/AML.T0018/ 1/3Home Techniques
Backdoor ML Model󰅂 󰅂
Backdoor ML Model 󰅂
Summary
Adversaries may introduce a backdoor into a ML model. A backdoored model
operates performs as expected under typical conditions, but will produce the
adversary's desired output when a trigger is introduced to the input data. A
backdoored model provides the adversary with a persistent artifact on the victim
system. The embedded vulnerability is typically activated at a later time by data
samples with an Insert Backdoor Trigger
ID: AML.T0018
Mitigation: Vulnerability Scanning
Subtechniques: Backdoor ML Model: Poison ML Model, Backdoor ML Model: Inject
Payload
Tactics: ML Attack Staging, Persistence
Mitigation󰅃
Vulnerability Scanning
Subtechniques 󰅃
Backdoor ML Model: Poison ML Model󰍜 󰇙3/22/24, 2:25 PM Backdoor ML Model | MITRE ATLAS™
https://atlas.mitre.org/techniques/AML.T0018/ 2/3Backdoor ML Model: Inject Payload
Tactics󰅃
ML Attack Staging
Persistence
Join our collaborative community
to shape future tool and
framework developments in AI
security , threat mitigation, bias,
privacy and other critical aspects
of AI assurance.www .mitre.org
© 2021-2024 The MITRE Corporation. All Rights Reserved.
Approved for Public Release; Distribution Unlimited. Case Number 21-2363.
MITRE ATLAS™ and MITRE ATT&CK are a trademark and registered trademark of The MITRE
Corporation.
Privacy Policy | Terms of Use | Manage CookiesCONNECT WITH US
󰅂
®󰍜 󰇙3/22/24, 2:25 PM Backdoor ML Model | MITRE ATLAS™
https://atlas.mitre.org/techniques/AML.T0018/ 3/3󰍜 󰇙