3/7/24, 3:57 PM Poison Training Data | MITRE ATLAS™
https://atlas.mitre.org/techniques/AML.T0020/ 1/2Home Techniques Poison Training Data
Poison Training Data
Summary󰅂 󰅂
Adversaries may attempt to poison datasets used by a ML
model by modifying the underlying data or its labels. This
allows the adversary to embed vulnerabilities in ML models
trained on the data that may not be easily detectable. Data
poisoning attacks may or may not require modifying the
labels. The embedded vulnerability is activated at a later
time by data samples with an Insert Backdoor Trigger
Poisoned data can be introduced via ML Supply Chain
Compromise or the data may be poisoned after the
adversary gains Initial Access to the system.ID: AML.T0020
Case Studies: VirusTotal
Poisoning , Tay Poisoning
Mitigations: Limit Model
Artifact Release , Control
Access to ML Models and
Data at Rest , Sanitize
Training Data
Tactics: Resource
Development , Persistence
Case Studies󰅀
VirusTotal Poisoning
Tay Poisoning
Mitigations󰅀
Limit Model Artifact Release
Control Access to ML Models and Data at Rest
Sanitize Training Data󰍜 Matrices Navigator Tactics Techniques Mitigations Case Studies󰍝
This website utilizes technologies such as cookies to enable essential site functionality , as well as
for analytics, personalization, and targeted advertising purposes. To learn more, view the following
link: Privacy Policy
Manage Preferences3/7/24, 3:57 PM Poison Training Data | MITRE ATLAS™
https://atlas.mitre.org/techniques/AML.T0020/ 2/2Tactics󰅀
Resource Development
Persistence
MITRE ATLAS™ and MITRE ATT&CK are a trademark and registered
trademark of The MITRE Corporation.®
PRIVACY POLICY TERMS OF USE MANAGE COOKIESCONTACT󰍜 Matrices Navigator Tactics Techniques Mitigations Case Studies󰍝
This website utilizes technologies such as cookies to enable essential site functionality , as well as
for analytics, personalization, and targeted advertising purposes. To learn more, view the following
link: Privacy Policy